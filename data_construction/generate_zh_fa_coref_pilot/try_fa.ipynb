{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy, benepar\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "from supar.utils import Tree\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s09e03c09t', 's09e03c10t', 's09e03c11t', 's09e03c12t', 's09e03c13t', 's09e04c00t', 's09e04c01t', 's09e04c02t', 's09e04c03t', 's09e04c04t', 's09e04c05t', 's09e04c06t', 's09e04c07t', 's09e04c08t', 's09e04c09t', 's09e04c10t', 's09e04c11t', 's09e04c12t', 's09e07c00t', 's09e07c01t', 's09e07c02t', 's09e07c03t', 's09e07c04t', 's09e07c05t', 's09e07c06t', 's09e07c07t', 's09e07c08t', 's09e07c09t', 's09e07c10t', 's09e09c00t', 's09e09c01t', 's09e09c02t', 's09e09c03t', 's09e09c04t', 's09e09c05t', 's09e09c06t', 's09e09c07t', 's09e09c08t', 's09e09c09t', 's09e09c10t', 's09e09c11t', 's09e09c12t', 's09e09c13t', 's09e10c00t', 's09e10c01t', 's09e10c02t', 's09e10c03t', 's09e10c04t', 's09e10c05t', 's09e10c06t', 's09e10c07t', 's09e10c08t', 's09e10c09t', 's09e10c10t', 's09e10c11t', 's09e10c12t', 's09e10c13t', 's09e10c14t', 's09e11c00t', 's09e11c01t', 's09e11c02t', 's09e11c03t', 's09e11c04t', 's09e11c05t', 's09e11c06t', 's09e11c07t', 's09e11c08t', 's09e11c09t', 's09e11c10t', 's09e11c11t', 's01e14c14f', 's01e14c15f', 's09e11c12t', 's09e11c13t', 's09e11c14t', 's09e11c15t', 's09e11c16t', 's09e11c17t', 's09e12c00t', 's09e12c01t', 's09e12c02t', 's09e12c03t', 's09e12c04t', 's09e12c05t', 's09e12c06t', 's09e12c09t', 's09e12c10t', 's09e12c11t', 's09e12c12t', 's09e12c13t', 's09e12c14t', 's09e12c15t', 's09e16c00t', 's09e16c01t', 's09e16c02t', 's09e16c03t', 's09e16c04t', 's09e16c05t', 's09e16c06t', 's09e16c07t', 's09e16c08t', 's09e16c09t', 's09e16c10t', 's09e16c11t', 's09e16c12t', 's09e16c13t', 's09e16c14t', 's09e16c15t', 's01e13c00f', 's01e13c01f', 's01e13c02f', 's01e13c03f', 's01e13c04f', 's01e13c05f', 's01e13c06f', 's01e13c07f', 's01e13c08f', 's01e13c09f', 's01e13c10f', 's01e13c11f', 's01e14c00f', 's01e14c01f', 's01e14c02f', 's01e14c03f', 's01e14c04f', 's01e14c05f', 's01e14c06f', 's01e14c07f', 's01e14c08f', 's01e14c09f', 's01e14c10f', 's01e14c11f', 's01e14c12f', 's01e14c13f']\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "with open('data/parallel_corpus/split_dict.pkl', 'rb') as f:\n",
    "    all_scene_ids = pkl.load(f)['test']\n",
    "print(all_scene_ids)\n",
    "print(len(all_scene_ids))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fa_tokenizer exists in /Users/boyuanzheng/.pernlp/fa_tokenizer.pt\n",
      "Model fa_mwt exists in /Users/boyuanzheng/.pernlp/fa_mwt.pt\n",
      "Model fa_lemmatizer exists in /Users/boyuanzheng/.pernlp/fa_lemmatizer.pt\n",
      "Model parsbert exists in /Users/boyuanzheng/.pernlp/parsbert.tar.gz\n",
      "Model dependencyparser exists in /Users/boyuanzheng/.pernlp/dependencyparser.pt\n",
      "2022-11-24 18:42:59,602 loading file /Users/boyuanzheng/.conda/envs/multi_coref/lib/python3.8/site-packages/dadmatools/saved_models/dependencyparser/dependencyparser.pt\n",
      "Model parsbert exists in /Users/boyuanzheng/.pernlp/parsbert.tar.gz\n",
      "Model postagger exists in /Users/boyuanzheng/.pernlp/postagger.pt\n",
      "2022-11-24 18:43:09,836 loading file /Users/boyuanzheng/.conda/envs/multi_coref/lib/python3.8/site-packages/dadmatools/saved_models/postagger/postagger.pt\n",
      "Model fa_constituency exists in /Users/boyuanzheng/.pernlp/fa_constituency.pt\n"
     ]
    }
   ],
   "source": [
    "import dadmatools.pipeline.language as language\n",
    "pips = 'tok,lem,pos,dep,cons'\n",
    "nlp = language.Pipeline(pips)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boyuanzheng/.conda/envs/multi_coref/lib/python3.8/site-packages/dadmatools/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  prevK = bestScoresId // numWords\n",
      "[2022-11-25 21:41:02,000 INFO] [Ensembling dict with seq2seq lemmatizer...]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('از قصهٔ کودکیشان که می‌گفت، گاهی حرص می‌خورد!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['از', 'قصهٔ', 'کودکی', 'شان', 'که', 'می\\u200cگفت', '،', 'گاهی', 'حرص', 'می\\u200cخورد', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for item in doc:\n",
    "    tokens.append(item.text)\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP (NP (_ از) (_ قصهٔ) (_ کودکی) (_ شان) (_ که) (NP (_ می‌گفت) (NP (_ ،) (NP (_ گاهی) (NP (_ حرص) (_ می‌خورد))))) (_ !)))\n",
      "[(0, 11, 'TOP'), (0, 11, 'NP'), (5, 10, 'NP'), (6, 10, 'NP'), (7, 10, 'NP'), (8, 10, 'NP')]\n",
      "(0, 11, 'TOP')\n",
      "از قصهٔ کودکی شان که می‌گفت ، گاهی حرص می‌خورد !\n",
      "\n",
      "(0, 11, 'NP')\n",
      "از قصهٔ کودکی شان که می‌گفت ، گاهی حرص می‌خورد !\n",
      "\n",
      "(5, 10, 'NP')\n",
      "می‌گفت ، گاهی حرص می‌خورد\n",
      "\n",
      "(6, 10, 'NP')\n",
      "، گاهی حرص می‌خورد\n",
      "\n",
      "(7, 10, 'NP')\n",
      "گاهی حرص می‌خورد\n",
      "\n",
      "(8, 10, 'NP')\n",
      "حرص می‌خورد\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent_constituency in doc._.constituency:\n",
    "    print(sent_constituency)\n",
    "    tree = nltk.Tree.fromstring(str(sent_constituency))\n",
    "    constituents = Tree.factorize(tree)\n",
    "    print(constituents)\n",
    "    for item in constituents:\n",
    "        print(item)\n",
    "        print(\" \".join(tokens[item[0]: item[1]]))\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-25 21:28:05,974 INFO] [Ensembling dict with seq2seq lemmatizer...]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\" \".join(['میشه', 'سه', 'تا', 'شکلات', 'به', 'ما', 'بدید', '؟', 'می', 'بَریم', '!']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-25 21:32:03,074 INFO] [Ensembling dict with seq2seq lemmatizer...]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"داره سوال انحرافی میپرسه ، مگه نه ؟\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP (NP (_ داره) (_ سوال) (_ انحرافی) (NP (_ میپرسه) (NP (_ ،) (NP (_ مگه) (NP (_ نه) (_ ؟)))))))\n"
     ]
    }
   ],
   "source": [
    "for sent_constituency in doc._.constituency:\n",
    "    print(sent_constituency)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "sent_constituency = doc._.constituency[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP (NP (_ میشه) (_ سه) (_ تا) (_ شکلات) (NP (_ به) (NP (_ ما) (NP (_ بدید) (NP (_ ؟) (NP (_ می) (_ بَریم)))))) (_ !)))\n"
     ]
    }
   ],
   "source": [
    "print(sent_constituency)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP (NP (_ میشه) (_ سه) (_ تا) (_ شکلات) (NP (_ به) (NP (_ ما) (NP (_ بدید) (NP (_ ؟) (NP (_ می) (_ بَریم)))))) (_ !)))\n"
     ]
    }
   ],
   "source": [
    "print(str(sent_constituency))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import nltk\n",
    "tree = nltk.Tree.fromstring(str(sent_constituency))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tree.Tree'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tree))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'supar.utils.transform.TreeSentence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sent_constituency))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "\n",
    "factorized_tree = Tree.factorize(tree)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 11, 'TOP'), (0, 11, 'NP'), (5, 10, 'NP'), (6, 10, 'NP'), (7, 10, 'NP'), (8, 10, 'NP')]\n"
     ]
    }
   ],
   "source": [
    "print(factorized_tree)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP (NP (_ از) (_ قصهٔ) (_ کودکی) (_ شان) (_ که) (NP (_ می‌گفت) (NP (_ ،) (NP (_ گاهی) (NP (_ حرص) (_ می‌خورد))))) (_ !)))\n",
      "<class 'supar.utils.transform.TreeSentence'>\n"
     ]
    }
   ],
   "source": [
    "print(sent_constituency[0])\n",
    "print(type(sent_constituency[0]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "[E046] Can't retrieve unregistered extension attribute 'constituents'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/w9/673mfrb56v7dvx7hhvw7s6240000gn/T/ipykernel_89535/2323259259.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mconstituents\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0msent\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msents\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstituents\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m         \u001B[0mconstituents\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtoken\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtoken\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtoken\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/multi_coref/lib/python3.8/site-packages/spacy/tokens/underscore.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getattr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extensions\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 33\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mErrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mE046\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m         \u001B[0mdefault\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgetter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msetter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extensions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mgetter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: [E046] Can't retrieve unregistered extension attribute 'constituents'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "source": [
    "constituents = []\n",
    "for sent in list(doc.sents):\n",
    "    for token in sent._.constituents:\n",
    "        constituents.append((token.text, token.start, token.end, token._.labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
